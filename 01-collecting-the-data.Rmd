# Collecting the Data

First things first, we need to acquire yearly datasets of crashes from the ARIES repository. They let you do so either by downloading csv files or by querying their API. I started with the API first, but ran into trouble when certain years wouldn't respond to my queries. I found that these same datasets would [return an error message](https://i.postimg.cc/wvxV7W9b/ARIES-server-not-responding.png) when trying to preview on the repository as well. Here we will take the approach of downloading all the datasets to disk as csv files before working with them.

Start by loading the needed R libraries.

```{r message=FALSE, warning=FALSE}
library(readr) # "The goal of 'readr' is to provide a fast and friendly way to read rectangular data (like 'csv', 'tsv', and 'fwf')."
library(dplyr) # "A fast, consistent tool for working with data frame like objects, both in memory and out of memory.
library(lubridate) # Lubridate makes it easier to do the things R does with date-times and possible to do the things R does not.
library(DBI) # A database interface definition for communication between R and relational database management systems.
```

## Download the yearly datasets

```{r eval=FALSE}
# Make a reference vector of years for the datasets
years <- 2007:2019

# Here is a vector of URL's for each year's repository of data
urls <- c(
    "https://hub.mph.in.gov/dataset/4ac55064-1f0d-4e5e-aeee-12faf28d6175/resource/994487c5-5d44-4fb9-ae9d-84ca75659bf0/download/aries_crash_data_2007.csv",
    "https://hub.mph.in.gov/dataset/4ac55064-1f0d-4e5e-aeee-12faf28d6175/resource/e4e56445-8cb6-4fc5-955c-7a2331684279/download/aries_crash_data_2008.csv",
    "https://hub.mph.in.gov/dataset/4ac55064-1f0d-4e5e-aeee-12faf28d6175/resource/881391be-d712-44b4-bfd0-ef9f018a4e4b/download/aries_crash_data_2009.csv",
    "https://hub.mph.in.gov/dataset/4ac55064-1f0d-4e5e-aeee-12faf28d6175/resource/46eb8985-f5b5-4635-9d6c-769dbd05fa02/download/aries_crash_data_2010.csv",
    "https://hub.mph.in.gov/dataset/4ac55064-1f0d-4e5e-aeee-12faf28d6175/resource/32ecfbfa-cf4b-4f64-af48-e1a624ae5ba4/download/aries_crash_data_2011.csv",
    "https://hub.mph.in.gov/dataset/4ac55064-1f0d-4e5e-aeee-12faf28d6175/resource/c2727405-925d-48fe-a8c1-06058ee65a25/download/aries_crash_data_2012.csv",
    "https://hub.mph.in.gov/dataset/4ac55064-1f0d-4e5e-aeee-12faf28d6175/resource/ca9adbd5-001e-49e7-a850-f9f3471eb2db/download/aries_crash_data_2013.csv",
    "https://hub.mph.in.gov/dataset/4ac55064-1f0d-4e5e-aeee-12faf28d6175/resource/a5262209-109c-49cd-b6a9-a72970dc1cf5/download/aries_crash_data_2014.csv",
    "https://hub.mph.in.gov/dataset/4ac55064-1f0d-4e5e-aeee-12faf28d6175/resource/7fd801c4-4cf3-4e18-a949-a4d21401d798/download/aries_crash_data_2015.csv",
    "https://hub.mph.in.gov/dataset/4ac55064-1f0d-4e5e-aeee-12faf28d6175/resource/88646815-5b52-433b-9609-c75500e48e4c/download/aries_crash_data_2016.csv",
    "https://hub.mph.in.gov/dataset/4ac55064-1f0d-4e5e-aeee-12faf28d6175/resource/911880b1-d0bb-4168-a5c1-a52dcc291445/download/aries_crash_data_2017.csv",
    "https://hub.mph.in.gov/dataset/4ac55064-1f0d-4e5e-aeee-12faf28d6175/resource/cc90589c-72d8-4d92-a5fe-73254b555c73/download/aries_crash_data_2018.csv",
    "https://hub.mph.in.gov/dataset/4ac55064-1f0d-4e5e-aeee-12faf28d6175/resource/7081439e-33c9-45f5-9c0b-86d8a8c49252/download/aries_crash_data_2019.csv"
)

# Make a new folder for the data files
system("mkdir raw-ARIES")

# Download the CSV files
for (i in 1:13) {
    download.file(url = urls[i], destfile = paste0("raw-ARIES/aries-crash-data-",years[i],".csv"))
}
```

## Instruct R on how to parse the datasets

CSV files are in a simple-text spreadsheet format. They don't give much contextual information. For example, R needs to know what kind of variable each column corresponds to. Normally it can infer the type on its own. But we have so much missing data in these files, R hiccups when trying to assign a type. The next block of code walks through how to manually type each column.

You may notice that we are telling R to skip many of the columns it will encounter. This is because these columns are duplicates that store the same information in different formats. We will only keep one of the respective columns when these situations arise.

```{r}
# Tell the read_csv function how we want it to parse types for each column of the csv files. 
columnParsing <- cols(INDEXING_NUMBER = col_double(),
                       INDIVIDUAL_MR_RECORD = col_double(),
                       UNIT_MR_NUMBER = col_double(),
                       STATUSCDE = col_character(),
                       PERSONNMB = col_double(),
                       PERSONTYPECDE = col_skip(),
                       PERSONTYPEDESCR = col_character(),
                       GENDERCDE = col_character(),
                       AGE_GRP = col_character(),
                       POSINVEHCDE = col_skip(),
                       POSINVEHDESCR = col_character(),
                       EJECTTRAPCDE = col_skip(),
                       EJECTTRAPDESCR = col_character(),
                       SAFETYEQUUSEDCDE = col_skip(),
                       SAFETYEQUUSEDDESCR = col_character(),
                       SAFETYEQUEFFIND = col_character(),
                       INJSTATUSCDE = col_skip(),
                       INJSTATUSDESCR = col_character(),
                       INJNATURECDE = col_skip(),
                       INJNATUREDESCR = col_character(),
                       INJLOCCDE = col_skip(),
                       INJLOCCDESCR = col_character(),
                       TESTGIVENCDE = col_skip(),
                       TESTGIVENDESCR = col_character(),
                       RESULTALCHTXT = col_double(),
                       RESULTDRUGIND = col_character(),
                       AGENCYORITXT = col_skip(),
                       AGENCYORIDESCR = col_character(),
                       COUNTYCDE = col_skip(),
                       COUNTY_STATE = col_skip(),
                       COUNTYDESCR = col_character(),
                       CITYCDE = col_skip(),
                       CITYDESCR = col_character(),
                       COLLDTE = col_character(),
                       COLLISION_DAY = col_character(),
                       COLLISION_MONTH = col_character(),
                       COLLISION_YEAR = col_double(),
                       COLLISION_TIME = col_character(),
                       COLLISION_TIME_AM_PM = col_character(),
                       MOTORVEHINVOLVEDNMB = col_double(),
                       TRAILERSINVOLVEDNMB = col_double(),
                       INJUREDNMB = col_double(),
                       DEADNMB = col_double(),
                       DEERNMB = col_double(),
                       RDWYSUFFIXTXT = col_character(),
                       RDWYRAMPTXT = col_character(),
                       INTERINTERCHANGETXT = col_character(),
                       INCORPLIMITIND = col_character(),
                       PROPDAMAGECDE = col_skip(),
                       PROPDAMAGEDESCR = col_character(),
                       LATDECIMALNMB = col_double(),
                       LONGDECIMALNMB = col_double(),
                       TRAFFICCNTLOPIND = col_character(),
                       AGGRESSIVEDRIVEIND = col_character(),
                       HITRUNIND = col_character(),
                       SCHOOLZONEIND = col_character(),
                       RUMBLESTRIPIND = col_character(),
                       CONSTRUCTIND = col_character(),
                       LIGHTCONDCDE = col_skip(),
                       LIGHTCONDDESCR = col_character(),
                       WEATHERCDE = col_skip(),
                       WEATHERDESCR = col_character(),
                       SURFACETYPECDE_CONDDESCR = col_character(),
                       SURFACETYPECDE = col_skip(),
                       SURFACETYPEDESCR = col_character(),
                       PRIMARYFACTORCDE = col_skip(),
                       PRIMARYFACTORDESCR = col_character(),
                       MANNERCOLLCDE = col_skip(),
                       MANNERCOLLDESCR = col_character(),
                       TIMENOTIFIEDTXT = col_character(),
                       TIMENOTIFIEDAMPMTXT = col_character(),
                       TIMEARRIVEDTXT = col_character(),
                       TIMEARRIVEDAMPMTXT = col_character(),
                       INVESTCOMPLETEIND = col_character(),
                       PHOTOSTAKENIND = col_character(),
                       UNIQUELOCATIONID = col_character(),
                       STATEPROPIND = col_character(),
                       TRAFFICCNTRLCDE = col_skip(),
                       TRAFFICCNTRLDESCR = col_character(),
                       UNITNMB = col_double(),
                       UNIT_VEHICLE_NUMBER = col_double(),
                       UNITTYPECDE = col_skip(),
                       UNITTYPEDESCR = col_character(),
                       VEHYEARTXT = col_double(),
                       VEHMAKETXT = col_character(),
                       VEHMODELTXT = col_character(),
                       OCCUPSNMB = col_double(),
                       VEHLICSTATECDE = col_character(),
                       VEHLICSTATEDESCR = col_skip(),
                       AXELSTXT = col_double(),
                       SPEEDLIMITTXT = col_character(),
                       TOWEDIND = col_character(),
                       VEHUSECDE = col_skip(),
                       VEHUSEDESCR = col_character(),
                       ROADTYPECDE = col_skip(),
                       ROADTYPEDESCR = col_character(),
                       TRAVDIRCDE = col_character(),
                       TRAVDIRDESCR = col_skip(),
                       EMGERENCY_RUN = col_character(),
                       FIREIND = col_character(),
                       COLLEVENTCDE = col_skip(),
                       COLLEVENTDESCR = col_character(),
                       PRECOLLACTCDE = col_skip(),
                       PRECOLLACTDESCR = col_character(),
                       DISTRICT = col_character(),
                       DISTRICT_NUM = col_skip(),
                       SUBDISTRICT = col_character()
                       )
```

## Prepare a database for storing the data

We'll be using the [SQLite database system](https://sqlite.org/index.html) for storing our data.

```{r}
# Write and initialize a connection to the database
mydb <- dbConnect(RSQLite::SQLite(), "ARIES.sqlite")
```

At this point the database is empty:

```{r}
# List tables stored in our database
dbListTables(mydb)
```

```{r eval=FALSE, include=FALSE}
# Delete table if needed
dbRemoveTable(mydb, "combinedARIES")
```

## Feed records into the database

Our empty database is hungry! To start things off, let's just feed in a single year's worth of records. Before we write the records in, we'll do some light data cleaning as explained in the code comments below.

>You may think it's a little weird to convert COLLDTE variable into a "date" type then convert it back into "character" text. It turns out that the CSV files in ARIES store their dates in different formats:
>
>- 2007-2016: Year.Month.Day
>- 2017-2018: Year-Month-Day
>- 2019: Month/Day/Year
>
>By first converting the variable into the R "date" type, I'm standardizing each year so that the format is the same. It'll make things easier down the line.

```{r}
# Parse the first csv file for 2007
Crashes2007 <- readr::read_csv("raw-ARIES/aries_crash_data_2007.csv", col_types = columnParsing)

# Standardize the date format
Crashes2007$COLLDTE <- Crashes2007$COLLDTE %>% ymd() %>% as.character()

# Clean the table
cleanCrashes2007 <- Crashes2007 %>%
    # Delete duplicate rows
    distinct() %>%
    # Remove rows that don't have a valid latitude, longitude, and date
    filter(!is.na(LATDECIMALNMB) & 
           !is.na(LONGDECIMALNMB) &
           !is.na(COLLDTE) &
           LATDECIMALNMB != 0 & 
           LONGDECIMALNMB != 0)

# Write 2007 records into the database
dbWriteTable(mydb, "combinedARIES", cleanCrashes2007)
```


